{"model_config": null, "model_parallel_size": 1, "fp16": false, "do_train": false, "do_valid": false, "do_eval": true, "train_ratio": 1, "valid_ratio": 1, "test_ratio": 1, "batch_size": 8, "gradient_accumulation_steps": 1, "train_iters": -1, "epochs": 3, "weight_decay": 0.01, "checkpoint_activations": false, "checkpoint_num_layers": 1, "clip_grad": 1.0, "seed": 422, "lr_decay_style": "linear", "lr": 0.0001, "warmup": 0.01, "load": null, "load_optimizer_states": false, "load_lr_scheduler_states": false, "no_load_strict": false, "save": "eval_args", "save_interval": 10, "log_file": "./logs/eval.log", "log_interval": 5, "distributed_backend": "nccl", "local_rank": 0, "eval_batch_size": 8, "eval_interval": 10, "eval_generation": false, "do_sample": false, "temperature": 0.9, "top_p": 0.9, "top_k": 0, "max_generation_length": 128, "min_generation_length": 2, "num_beams": 1, "no_repeat_ngram_size": 3, "repetition_penalty": 1.2, "early_stopping": false, "length_penalty": 1.8, "rule_path": null, "data_path": "/opt/data/private/nlp03/kdwang/dialog_projects/EVA/data/kdconv", "cache_path": "/opt/data/private/nlp03/kdwang/dialog_projects/EVA/cache/kdconv", "tokenizer_path": null, "data_ext": ".txt", "num_workers": 2, "enc_seq_length": 512, "dec_seq_length": 512, "cuda": true, "rank": 0, "world_size": 1}